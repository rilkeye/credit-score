{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib\n",
    "import pydot\n",
    "import re\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12\n",
    "\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import seaborn as sns\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import export_graphviz, DecisionTreeClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, GridSearchCV\n",
    "#显示所有列\n",
    "pd.set_option('display.max_columns', None)\n",
    "#显示所有行\n",
    "pd.set_option('display.max_rows', None)\n",
    "#设置value的显示长度为100，默认为50\n",
    "pd.set_option('max_colwidth',100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path of datasets\n",
    "path_train = 'data/train_dataset.csv'\n",
    "path_test  = 'data/test_dataset.csv'\n",
    "\n",
    "def display_confusion_matrix(sample_test, prediction, score=None):\n",
    "    cm = metrics.confusion_matrix(sample_test, prediction)\n",
    "    plt.figure(figsize=(9,9))\n",
    "    sns.heatmap(cm, annot=True, fmt=\".3f\", linewidths=.5, square=True, cmap='Blues_r')\n",
    "    plt.ylabel('Actual label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    if score:\n",
    "        all_sample_title = 'Accuracy Score: {0}'.format(score)\n",
    "        plt.title(all_sample_title, size = 15)\n",
    "    print(metrics.classification_report(sample_test, prediction))\n",
    "    \n",
    "def visualize_tree(tree, feature_names):\n",
    "    \"\"\"Create tree png using graphviz\"\"\"\n",
    "    with open(\"dt.dot\", 'w') as f:\n",
    "        export_graphviz(tree, out_file=f,\n",
    "                        feature_names=feature_names)\n",
    "\n",
    "    command = [\"dot\", \"-Tpng\", \"dt.dot\", \"-o\", \"dt.png\"]\n",
    "    try:\n",
    "        subprocess.check_call(command)\n",
    "    except:\n",
    "        exit(\"Could not run dot, ie graphviz, to \"\n",
    "             \"produce visualization\")\n",
    "        \n",
    "# Create table for missing data analysis\n",
    "def draw_missing_data_table(df):\n",
    "    total = df.isnull().sum().sort_values(ascending=False)\n",
    "    percent = (df.isnull().sum()/df.isnull().count()).sort_values(ascending=False)\n",
    "    missing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n",
    "    return missing_data\n",
    "\n",
    "# Function with standardize a dataframe by setting mean to 0 and var to 1\n",
    "def standardize(df, target=None, categorical=None):\n",
    "    \n",
    "    standardize_df = df\n",
    "    \n",
    "    if target:\n",
    "        target_serie = standardize_df[target] # Separating out the target before standardizing\n",
    "        standardize_df = standardize_df.drop([target],  axis=1)\n",
    "    \n",
    "    if categorical:\n",
    "        cat_serie = standardize_df[categorical] # Separating out categorical feature(s) before standardizing\n",
    "        standardize_df = standardize_df.drop([categorical],  axis=1)\n",
    "\n",
    "    # Standardizing the features\n",
    "    scaled_values = StandardScaler().fit_transform(standardize_df.values)\n",
    "    standardize_df = pd.DataFrame(scaled_values, index=standardize_df.index, columns=standardize_df.columns)\n",
    "    \n",
    "    if target:\n",
    "        standardize_df = standardize_df.join(target_serie)\n",
    "        \n",
    "    if categorical:\n",
    "        standardize_df = standardize_df.join(cat_serie)\n",
    "    \n",
    "    return standardize_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'data/train_dataset.csv' does not exist",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-1bfa5ca6a8d5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_df_raw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mtrain_df_raw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, doublequote, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    676\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 678\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    679\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    680\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    438\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    439\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 440\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    441\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    442\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    785\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    786\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 787\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    788\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    789\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1012\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'c'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1013\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'c'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1014\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1015\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1016\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'python'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1706\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'usecols'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1707\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1708\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1709\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1710\u001b[0m         \u001b[0mpassed_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnames\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: File b'data/train_dataset.csv' does not exist"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "train_df_raw = pd.read_csv(path_train)\n",
    "train_df_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "用户编码去掉\n",
    "用户实名制是否通过核实去掉\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_df_raw' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-839d7331db2f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_df_raw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdescribe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'train_df_raw' is not defined"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "train_df_raw.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_df_raw' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-db21b0bf8662>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mStratifiedKFold\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilterwarnings\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'ignore'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[0msns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcountplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_df_raw\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'是否4G不健康客户'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'train_df_raw' is not defined"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "import gc\n",
    "import os\n",
    "import logging\n",
    "import datetime\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import lightgbm as lgb\n",
    "from tqdm import tqdm_notebook\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "warnings.filterwarnings('ignore')\n",
    "sns.countplot(train_df_raw['是否4G不健康客户'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50000 entries, 0 to 49999\n",
      "Data columns (total 30 columns):\n",
      "用户编码               50000 non-null object\n",
      "用户实名制是否通过核实        50000 non-null int64\n",
      "用户年龄               50000 non-null int64\n",
      "是否大学生客户            50000 non-null int64\n",
      "是否黑名单客户            50000 non-null int64\n",
      "是否4G不健康客户          50000 non-null int64\n",
      "用户网龄（月）            50000 non-null int64\n",
      "用户最近一次缴费距今时长（月）    50000 non-null int64\n",
      "缴费用户最近一次缴费金额（元）    50000 non-null float64\n",
      "用户近6个月平均消费值（元）     50000 non-null float64\n",
      "用户账单当月总费用（元）       50000 non-null float64\n",
      "用户当月账户余额（元）        50000 non-null int64\n",
      "缴费用户当前是否欠费缴费       50000 non-null int64\n",
      "用户话费敏感度            50000 non-null int64\n",
      "当月通话交往圈人数          50000 non-null int64\n",
      "是否经常逛商场的人          50000 non-null int64\n",
      "近三个月月均商场出现次数       50000 non-null int64\n",
      "当月是否逛过福州仓山万达       50000 non-null int64\n",
      "当月是否到过福州山姆会员店      50000 non-null int64\n",
      "当月是否看电影            50000 non-null int64\n",
      "当月是否景点游览           50000 non-null int64\n",
      "当月是否体育场馆消费         50000 non-null int64\n",
      "当月网购类应用使用次数        50000 non-null int64\n",
      "当月物流快递类应用使用次数      50000 non-null int64\n",
      "当月金融理财类应用使用总次数     50000 non-null int64\n",
      "当月视频播放类应用使用次数      50000 non-null int64\n",
      "当月飞机类应用使用次数        50000 non-null int64\n",
      "当月火车类应用使用次数        50000 non-null int64\n",
      "当月旅游资讯类应用使用次数      50000 non-null int64\n",
      "信用分                50000 non-null int64\n",
      "dtypes: float64(3), int64(26), object(1)\n",
      "memory usage: 11.4+ MB\n"
     ]
    }
   ],
   "source": [
    "train_df_raw.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total</th>\n",
       "      <th>Percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>信用分</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>当月旅游资讯类应用使用次数</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>用户实名制是否通过核实</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>用户年龄</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>是否大学生客户</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>是否黑名单客户</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>是否4G不健康客户</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>用户网龄（月）</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>用户最近一次缴费距今时长（月）</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>缴费用户最近一次缴费金额（元）</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>用户近6个月平均消费值（元）</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>用户账单当月总费用（元）</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>用户当月账户余额（元）</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>缴费用户当前是否欠费缴费</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>用户话费敏感度</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>当月通话交往圈人数</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>是否经常逛商场的人</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>近三个月月均商场出现次数</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>当月是否逛过福州仓山万达</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>当月是否到过福州山姆会员店</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>当月是否看电影</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>当月是否景点游览</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>当月是否体育场馆消费</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>当月网购类应用使用次数</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>当月物流快递类应用使用次数</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>当月金融理财类应用使用总次数</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>当月视频播放类应用使用次数</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>当月飞机类应用使用次数</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>当月火车类应用使用次数</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>用户编码</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Total  Percent\n",
       "信用分                  0      0.0\n",
       "当月旅游资讯类应用使用次数        0      0.0\n",
       "用户实名制是否通过核实          0      0.0\n",
       "用户年龄                 0      0.0\n",
       "是否大学生客户              0      0.0\n",
       "是否黑名单客户              0      0.0\n",
       "是否4G不健康客户            0      0.0\n",
       "用户网龄（月）              0      0.0\n",
       "用户最近一次缴费距今时长（月）      0      0.0\n",
       "缴费用户最近一次缴费金额（元）      0      0.0\n",
       "用户近6个月平均消费值（元）       0      0.0\n",
       "用户账单当月总费用（元）         0      0.0\n",
       "用户当月账户余额（元）          0      0.0\n",
       "缴费用户当前是否欠费缴费         0      0.0\n",
       "用户话费敏感度              0      0.0\n",
       "当月通话交往圈人数            0      0.0\n",
       "是否经常逛商场的人            0      0.0\n",
       "近三个月月均商场出现次数         0      0.0\n",
       "当月是否逛过福州仓山万达         0      0.0\n",
       "当月是否到过福州山姆会员店        0      0.0\n",
       "当月是否看电影              0      0.0\n",
       "当月是否景点游览             0      0.0\n",
       "当月是否体育场馆消费           0      0.0\n",
       "当月网购类应用使用次数          0      0.0\n",
       "当月物流快递类应用使用次数        0      0.0\n",
       "当月金融理财类应用使用总次数       0      0.0\n",
       "当月视频播放类应用使用次数        0      0.0\n",
       "当月飞机类应用使用次数          0      0.0\n",
       "当月火车类应用使用次数          0      0.0\n",
       "用户编码                 0      0.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "draw_missing_data_table(train_df_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_df_raw' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-8017d26d1297>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_df_raw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'train_df_raw' is not defined"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "train_df_raw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(df):\n",
    "    \n",
    "    processed_df = df\n",
    "    \n",
    "    \n",
    "    \n",
    "    processed_df['进行过多少种高端消费（max：7）'] = processed_df['当月是否景点游览'] + processed_df['是否经常逛商场的人'] + \\\n",
    "                                     processed_df['当月是否逛过福州仓山万达'] + processed_df['当月是否到过福州山姆会员店'] + \\\n",
    "                                     processed_df['当月是否看电影'] + processed_df['当月是否景点游览'] + \\\n",
    "                                     processed_df['当月是否体育场馆消费']\n",
    "    \n",
    "    processed_df = processed_df.drop(columns=['当月是否景点游览', '是否经常逛商场的人', '当月是否逛过福州仓山万达',\n",
    "                                                '当月是否到过福州山姆会员店', '当月是否看电影', '当月是否景点游览',\n",
    "                                                '当月是否体育场馆消费'])\n",
    "    \n",
    " \n",
    "    processed_df['用户历史消费总额'] = processed_df['用户网龄（月）'] * processed_df['用户近6个月平均消费值（元）']\n",
    "    processed_df['用户消费趋势'] = np.where((processed_df['用户账单当月总费用（元）'] - processed_df['用户近6个月平均消费值（元）'])>=0,1,0)\n",
    "    processed_df['用户不良记录种类'] = processed_df['缴费用户当前是否欠费缴费'] + processed_df['是否4G不健康客户'] + \\\n",
    "                                       processed_df['是否黑名单客户']\n",
    "    \n",
    "    '''\n",
    "    processed_df['用户年龄'][processed_df['用户年龄'] >= 90] = None\n",
    "    processed_df['用户年龄'][processed_df['用户年龄'] <= 18] = None\n",
    "    processed_df = processed_df.fillna(processed_df['用户年龄'].mean())\n",
    "    '''\n",
    "    \n",
    "    '''\n",
    "    processed_df['用户互联网活跃度'] = processed_df['当月网购类应用使用次数'] + processed_df['当月物流快递类应用使用次数'] + \\\n",
    "                                     processed_df['当月金融理财类应用使用总次数'] + processed_df['当月视频播放类应用使用次数'] + \\\n",
    "                                     processed_df['当月飞机类应用使用次数'] + processed_df['当月火车类应用使用次数'] + \\\n",
    "                                     processed_df['当月旅游资讯类应用使用次数']\n",
    "    \n",
    "    processed_df['用户互联网活跃度'] = np.log(processed_df['用户互联网活跃度'])\n",
    "    print(processed_df['用户互联网活跃度'])\n",
    "    processed_df = processed_df.drop(columns=['当月网购类应用使用次数', '当月物流快递类应用使用次数', '当月金融理财类应用使用总次数',\n",
    "                                             '当月视频播放类应用使用次数', '当月飞机类应用使用次数', '当月火车类应用使用次数',\n",
    "                                             '当月旅游资讯类应用使用次数'])\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    def func1(age):\n",
    "        if age > 25 and age < 55:\n",
    "            return 3\n",
    "        elif age < 18 or age > 65:\n",
    "            return 1\n",
    "        else:\n",
    "            return 2\n",
    "            \n",
    "        \n",
    "    processed_df['用户消费能力等级（三级最高）'] = processed_df['用户年龄'].map(func1)\n",
    "    processed_df = processed_df.drop(columns=['用户年龄'])\n",
    "    '''\n",
    "    \n",
    "    # Drop useless columns\n",
    "    processed_df = processed_df.drop(['用户编码'], 1)\n",
    "    processed_df = processed_df.drop(['用户实名制是否通过核实'], 1)\n",
    "\n",
    "    return processed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_df_raw' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-3a5aa58db5ab>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_df_raw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreprocess_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_df_raw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'train_df_raw' is not defined"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "train_df_raw = preprocess_data(train_df_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_df_raw' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-8017d26d1297>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_df_raw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'train_df_raw' is not defined"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "train_df_raw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_df_raw' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-be9bec271089>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Let's divide the train dataset in two datasets to evaluate perfomance of machine learning models used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtrain_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_df_raw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'信用分'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mY\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'信用分'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_df_raw' is not defined"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "# Let's divide the train dataset in two datasets to evaluate perfomance of machine learning models used\n",
    "train_df = train_df_raw.copy()\n",
    "X = train_df.drop(['信用分'], 1)\n",
    "Y = train_df['信用分']\n",
    "\n",
    "\n",
    "# sc = StandardScaler()\n",
    "# X = pd.DataFrame(sc.fit_transform(X.values), index=X.index, columns=X.columns)\n",
    "    \n",
    "# Split dataset for prediction\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size=0.2, random_state=21)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_train, Y_train, test_size=0.25, random_state=21)\n",
    "\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_round = 1444\n",
    "params = {\n",
    "    'task': 'train',\n",
    "    'boosting_type': 'gbdt',  # GBDT算法为基础\n",
    "    'objective': 'regression',  # 回归任务\n",
    "    'metric': 'rmse',  # 评判指标\n",
    "    'max_bin': 255,  # 大会有更准的效果,更慢的速度\n",
    "    'learning_rate': 0.01,  # 学习率\n",
    "    'num_leaves': 40,  # 大会更准,但可能过拟合\n",
    "    'max_depth': 8,  # 小数据集下限制最大深度可防止过拟合,小于0表示无限制\n",
    "    'feature_fraction': 0.61,  # 如果 feature_fraction 小于 1.0, LightGBM 将会在每次迭代中随机选择部分特征.\n",
    "                              # 例如, 如果设置为 0.8, 将会在每棵树训练之前选择 80% 的特征. 可以处理过拟合\n",
    "    'bagging_freq': 5,  # 防止过拟合\n",
    "    'bagging_fraction': 0.75,  # 防止过拟合\n",
    "    'min_data_in_leaf': 21,  # 防止过拟合\n",
    "    'min_sum_hessian_in_leaf': 3.0,  # 防止过拟合\n",
    "    'n_estimator':1444,\n",
    "    'reg_alpha': 0.5, \n",
    "    'reg_lambda': 0.08,\n",
    "    'header': False  # 数据集是否带表头\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-89a53ca7ee85>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlightgbm\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mlgb\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mmodel_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'model.txt'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mtrain_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlgb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mY_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;31m# train_data.save_binary('data/train.bin')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "model_path = 'model.txt'\n",
    "train_data = lgb.Dataset(X_train, label=Y_train)\n",
    "# train_data.save_binary('data/train.bin')\n",
    "\n",
    "# 验证集加载\n",
    "valid_data = lgb.Dataset(X_val, label=Y_val, reference=train_data)\n",
    "# valid_data.save_binary('data/valid.bin')\n",
    "\n",
    "# Train & save model as model.txt\n",
    "bst = lgb.train(params=params, train_set=train_data, num_boost_round=num_round, valid_sets=None)\n",
    "bst.save_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predtion(dataset, model_path):\n",
    "    '''\n",
    "    :param dataset: 需要预测的数据\n",
    "    :param model_path: 模型路径\n",
    "    :return:\n",
    "    '''\n",
    "\n",
    "    bst = lgb.Booster(model_file=model_path)\n",
    "    pred = bst.predict(dataset)\n",
    "\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def give_a_mark(pred, label):\n",
    "    '''\n",
    "    MAE = 1/n * Sum(abs(pred(i) - y(i)))\n",
    "    Score = 1 / (1 + MAE)\n",
    "    '''\n",
    "    pred = np.array(pred)\n",
    "    label = np.array(label)\n",
    "    MAE = sum(abs(pred-label)) / float(len(pred))\n",
    "    score = 1.0 / (1.0 + MAE)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This Model gets score 0.06373299287214708\n"
     ]
    }
   ],
   "source": [
    "test_pred = make_predtion(X_test, model_path)\n",
    "score = give_a_mark(test_pred, Y_test)\n",
    "\n",
    "print(\"This Model gets score {}\".format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ncv_results = lgb.cv(\\n    params, train_data, num_boost_round=1175, nfold=5, stratified=False, shuffle=True, metrics='rmse',\\n    early_stopping_rounds=50, verbose_eval=50, show_stdv=True, seed=0)\\n\\nprint('best n_estimators:', len(cv_results['rmse-mean']))\\nprint('best cv score:', cv_results['rmse-mean'][-1])\\n\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "cv_results = lgb.cv(\n",
    "    params, train_data, num_boost_round=1175, nfold=5, stratified=False, shuffle=True, metrics='rmse',\n",
    "    early_stopping_rounds=50, verbose_eval=50, show_stdv=True, seed=0)\n",
    "\n",
    "print('best n_estimators:', len(cv_results['rmse-mean']))\n",
    "print('best cv score:', cv_results['rmse-mean'][-1])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nparams = {    'boosting_type': 'gbdt', \\n    'objective': 'regression', \\n\\n    'learning_rate': 0.01, \\n    'num_leaves': 40, \\n    'max_depth': 8,    'min_data_in_leaf': 20,    'subsample': 0.75, \\n    'colsample_bytree': 0.61, \\n    }\\n\\ndata_train = lgb.Dataset(X_train, Y_train, silent=True)\\ncv_results = lgb.cv(\\n    params, data_train, num_boost_round=10000, nfold=5, stratified=False, shuffle=True, metrics='rmse',\\n    early_stopping_rounds=50, verbose_eval=100, show_stdv=True)\\n\\nprint('best n_estimators:', len(cv_results['rmse-mean']))\\nprint('best cv score:', cv_results['rmse-mean'][-1])\\n\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "params = {    'boosting_type': 'gbdt', \n",
    "    'objective': 'regression', \n",
    "\n",
    "    'learning_rate': 0.01, \n",
    "    'num_leaves': 40, \n",
    "    'max_depth': 8,    'min_data_in_leaf': 20,    'subsample': 0.75, \n",
    "    'colsample_bytree': 0.61, \n",
    "    }\n",
    "\n",
    "data_train = lgb.Dataset(X_train, Y_train, silent=True)\n",
    "cv_results = lgb.cv(\n",
    "    params, data_train, num_boost_round=10000, nfold=5, stratified=False, shuffle=True, metrics='rmse',\n",
    "    early_stopping_rounds=50, verbose_eval=100, show_stdv=True)\n",
    "\n",
    "print('best n_estimators:', len(cv_results['rmse-mean']))\n",
    "print('best cv score:', cv_results['rmse-mean'][-1])\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
